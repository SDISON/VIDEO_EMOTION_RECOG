{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6JyhZUGlYHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_test\n",
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-4JBeNhMN0ouKnMTQ3_d-N8CnPKoRo3q' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-4JBeNhMN0ouKnMTQ3_d-N8CnPKoRo3q\" -O '/content/data_test.zip' && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-7EwEMEqE9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data-train\n",
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1IhQyxq4mKZdUOAz5Dw-_HY0ql3HvuMm4' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1IhQyxq4mKZdUOAz5Dw-_HY0ql3HvuMm4\" -O /content/dataset.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW2Y0tyaqwWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq '/content/dataset.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7C7rVGNnWnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_val\n",
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-1u-7qDEj7v-gG4gU2uQIVLyCXi2X98H' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-1u-7qDEj7v-gG4gU2uQIVLyCXi2X98H\" -O '/content/data_val.zip' && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxM6QESgm2iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq '/content/data_test.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81YJMybO5JgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -qq '/content/data_val.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSadA9IQ5JrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mv '/content/content/content/data/test' '/content/content/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arIU8xSGb-rY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d6a2948-ec2d-422d-cf40-c47b36579c6e"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from imutils import face_utils\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from numpy import array\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tqdm import tqdm\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjscjbG_cM1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONSTANT_FRAMES = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbh6wuPicTmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = layers.Input(name = 'input', shape=(224, 224, 1))\n",
        "\n",
        "block1 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block1_1')(input)\n",
        "block1 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block1_2')(block1)\n",
        "\n",
        "block2 =  layers.MaxPool2D(pool_size = (2, 2), strides = 2, name = 'block2_1')(block1)\n",
        "block2 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block2_2')(block2)\n",
        "block2 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block2_3')(block2)\n",
        "\n",
        "block3 =  layers.MaxPool2D(pool_size = (2, 2), strides = 2, name = 'block3_1')(block2)\n",
        "block3 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block3_2')(block3)\n",
        "block3 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block3_3')(block3)\n",
        "block3 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block3_4')(block3)\n",
        "\n",
        "block4 =  layers.MaxPool2D(pool_size = (2, 2), strides = 2, name = 'block4_1')(block3)\n",
        "block4 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block4_2')(block4)\n",
        "block4 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block4_3')(block4)\n",
        "block4 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block4_4')(block4)\n",
        "\n",
        "block5 =  layers.MaxPool2D(pool_size = (2, 2), strides = 2, name = 'block5_1')(block4)\n",
        "block5 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block5_2')(block5)\n",
        "block5 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block5_3')(block5)\n",
        "block5 =  layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'block5_4')(block5)\n",
        "\n",
        "block6 =  layers.MaxPool2D((2, 2), name = 'block6_1')(block5)\n",
        "\n",
        "fc6 = layers.Flatten(name = 'fc6')(block6)\n",
        "fc6 = layers.Dense(8,activation='softmax')(fc6)\n",
        "\n",
        "fc5 = layers.Flatten(name = 'fc5')(block5)\n",
        "fc5 = layers.Dense(8,activation='softmax')(fc5)\n",
        "\n",
        "block6 =  layers.UpSampling2D((4,4), interpolation = 'bilinear', name = 'up6_x4')(block6)\n",
        "block5 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up5_x2')(block5)\n",
        "concat5 = layers.Concatenate(name = 'concat5')([block6, block5, block4])\n",
        "concat5 = layers.Conv2D(64,(1,1), activation = 'relu')(concat5)\n",
        "fc4 = layers.Flatten(name = 'fc4')(concat5)\n",
        "fc4 = layers.Dense(8,activation='softmax')(fc4)\n",
        "\n",
        "block6 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up6_x8')(block6)\n",
        "block5 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up5_x4')(block5)\n",
        "concat4 = layers.Concatenate(name = 'concat4')([block6, block5, block3])\n",
        "concat4 = layers.Conv2D(32,(1,1), activation = 'relu')(concat4)\n",
        "fc3 = layers.Flatten(name = 'fc3')(concat4)\n",
        "fc3 = layers.Dense(8,activation='softmax')(fc3)\n",
        "\n",
        "block6 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up6_x16')(block6)\n",
        "block5 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up5_x8')(block5)\n",
        "block4 =  layers.UpSampling2D((4,4), interpolation = 'bilinear', name = 'up4_x4')(block4)\n",
        "block3 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up3_x2')(block3)\n",
        "concat3 = layers.Concatenate(name = 'concat3')([block6, block5, block4, block3, block2])\n",
        "concat4 = layers.Conv2D(8,(1,1), activation = 'relu')(concat3)\n",
        "fc2 = layers.Flatten(name = 'fc2')(concat3)\n",
        "fc2 = layers.Dense(8,activation='softmax')(fc2)\n",
        "\n",
        "block6 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up6_x32')(block6)\n",
        "block5 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up5_x16')(block5)\n",
        "block4 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up4_x8')(block4)\n",
        "block3 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up3_x4')(block3)\n",
        "concat2 = layers.Concatenate(name = 'concat2')([block6, block5, block4, block3, block1])\n",
        "concat2 = layers.Conv2D(8,(1,1), activation = 'relu')(concat2)\n",
        "fc1 = layers.Flatten(name = 'fc1')(concat2)\n",
        "fc1 = layers.Dense(8,activation='softmax')(fc1)\n",
        "\n",
        "block6 =  layers.UpSampling2D((1,1), interpolation = 'bilinear', name = 'up6__x32')(block6)\n",
        "block5 =  layers.UpSampling2D((1,1), interpolation = 'bilinear', name = 'up5__x16')(block5)\n",
        "block4 =  layers.UpSampling2D((1,1), interpolation = 'bilinear', name = 'up4__x8')(block4)\n",
        "block3 =  layers.UpSampling2D((1,1), interpolation = 'bilinear', name = 'up3__x4')(block3)\n",
        "block2 =  layers.UpSampling2D((2,2), interpolation = 'bilinear', name = 'up2_x2')(block2)\n",
        "concat1 = layers.Concatenate(name = 'concat1')([block6, block5, block4, block3, block2, block1])\n",
        "concat1 = layers.Conv2D(8,(1,1), activation = 'relu')(concat1)\n",
        "fc0 = layers.Flatten(name = 'fc0')(concat1)\n",
        "fc0 = layers.Dense(8,activation='softmax')(fc0)\n",
        "\n",
        "output = layers.Average()([fc0, fc1, fc2, fc3, fc4, fc5, fc6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJxTKbNpcq9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Model(input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQZZXDqTh7Xu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3d12a11d-6187-424a-f230-ecc8db05c27d"
      },
      "source": [
        "'''\n",
        "def myprint(s):\n",
        "    with open('modelsummary.txt','w+') as f:\n",
        "        print(s, file=f)\n",
        "#model.summary(print_fn=myprint)\n",
        "#model.summary(line_length=100)\n",
        "#x = model.summary()\n",
        "with open('out.txt', 'w') as f:\n",
        "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef myprint(s):\\n    with open('modelsummary.txt','w+') as f:\\n        print(s, file=f)\\n#model.summary(print_fn=myprint)\\n#model.summary(line_length=100)\\n#x = model.summary()\\nwith open('out.txt', 'w') as f:\\n    model.summary(print_fn=lambda x: f.write(x + '\\n'))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9f-dpDuvQwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LaIb00Zazoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for testing generator\n",
        "label_test = [i for i in range(2185, 2392)] #test\n",
        "start_test = {'surprised':2199, 'sad':2232, 'calm':2265, 'disgust':2279, 'angry':2312, 'fearful':2345, 'happy':2378, 'neutral':2392} #test\n",
        "mapping_test = {}\n",
        "i = 2185\n",
        "for key, value in start_test.items():\n",
        "    while(i<value):\n",
        "        mapping_test[i] = key\n",
        "        i += 1\n",
        "#batch size means video\n",
        "def imageLoader_test(label_test, batch_size):\n",
        "\n",
        "    L = len(label_test)\n",
        "\n",
        "    #this line is just to make the generator infinite, keras needs that    \n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "            X = Dataset_loader_X_test(label_test[batch_start:limit])\n",
        "            Y = Dataset_loader_Y_test(label_test[batch_start:limit])\n",
        "\n",
        "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
        "\n",
        "            batch_start += batch_size  \n",
        "            batch_end += batch_size\n",
        "def Dataset_loader_X_test(label_test):\n",
        "    RESIZE = 224\n",
        "    DIR = '/content/content/content/data/test/'\n",
        "    IMG = []\n",
        "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "    for i in label_test:\n",
        "        counter = 0\n",
        "        DIR2 = DIR + mapping_test[i] + '/' + str(i)\n",
        "        for IMAGE_NAME in (os.listdir(DIR2)):\n",
        "            if(counter == CONSTANT_FRAMES):\n",
        "                break\n",
        "            PATH = os.path.join(DIR2,IMAGE_NAME)\n",
        "            _, ftype = os.path.splitext(PATH)\n",
        "            if ftype == \".jpg\":\n",
        "                img = read(PATH)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img, (RESIZE,RESIZE))\n",
        "                IMG.append(np.array(img)/255.)\n",
        "            counter += 1\n",
        "    IMG = np.array(IMG)\n",
        "    IMG = IMG.reshape(IMG.shape[0], 224, 224, 1)\n",
        "    return IMG\n",
        "def Dataset_loader_Y_test(label_test):\n",
        "    DIR = '/content/content/content/data/test/'\n",
        "    y = []\n",
        "    dict_ = {'angry':1, 'sad':2, 'fearful':3, 'happy':4, 'neutral':5, 'surprised':6, 'disgust':7, 'calm':8}\n",
        "    for i in label_test:\n",
        "        counter = 0\n",
        "        DIR2 = DIR + mapping_test[i] + '/' + str(i)\n",
        "        for IMAGE_NAME in (os.listdir(DIR2)):\n",
        "            if(counter == CONSTANT_FRAMES):\n",
        "                break\n",
        "            temp = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "            temp[dict_[mapping_test[i]]-1] = 1\n",
        "            y.append(temp)\n",
        "            counter += 1\n",
        "    y = np.array(y)\n",
        "    y = y.reshape(y.shape[0], 8)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jp2EGxUsnH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for validation generator\n",
        "label_val = [i for i in range(1690, 2185)] #val\n",
        "start_val = {'surprised':1730, 'sad':1805, 'calm':1880, 'disgust':1920, 'angry':1995, 'fearful':2070, 'happy':2145, 'neutral':2185} #val\n",
        "mapping_val = {}\n",
        "i = 1690\n",
        "for key, value in start_val.items():\n",
        "    while(i<value):\n",
        "        mapping_val[i] = key\n",
        "        i += 1\n",
        "#batch size means video\n",
        "def imageLoader_val(label_val, batch_size):\n",
        "\n",
        "    L = len(label_val)\n",
        "\n",
        "    #this line is just to make the generator infinite, keras needs that    \n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "            X = Dataset_loader_X_val(label_val[batch_start:limit])\n",
        "            Y = Dataset_loader_Y_val(label_val[batch_start:limit])\n",
        "\n",
        "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
        "\n",
        "            batch_start += batch_size  \n",
        "            batch_end += batch_size\n",
        "def Dataset_loader_X_val(label_val):\n",
        "    RESIZE = 224\n",
        "    DIR = '/content/content/data/val/'\n",
        "    IMG = []\n",
        "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "    for i in label_val:\n",
        "        counter = 0\n",
        "        DIR2 = DIR + mapping_val[i] + '/' + str(i)\n",
        "        for IMAGE_NAME in (os.listdir(DIR2)):\n",
        "            if(counter == CONSTANT_FRAMES):\n",
        "                break\n",
        "            PATH = os.path.join(DIR2,IMAGE_NAME)\n",
        "            _, ftype = os.path.splitext(PATH)\n",
        "            if ftype == \".jpg\":\n",
        "                img = read(PATH)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img, (RESIZE,RESIZE))\n",
        "                IMG.append(np.array(img)/255.)\n",
        "            counter += 1\n",
        "    IMG = np.array(IMG)\n",
        "    IMG = IMG.reshape(IMG.shape[0], 224, 224, 1)\n",
        "    return IMG\n",
        "def Dataset_loader_Y_val(label_val):\n",
        "    DIR = '/content/content/data/val/'\n",
        "    y = []\n",
        "    dict_ = {'angry':1, 'sad':2, 'fearful':3, 'happy':4, 'neutral':5, 'surprised':6, 'disgust':7, 'calm':8}\n",
        "    for i in label_val:\n",
        "        counter = 0\n",
        "        DIR2 = DIR + mapping_val[i] + '/' + str(i)\n",
        "        for IMAGE_NAME in (os.listdir(DIR2)):\n",
        "            if(counter == CONSTANT_FRAMES):\n",
        "                break\n",
        "            temp = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "            temp[dict_[mapping_val[i]]-1] = 1\n",
        "            y.append(temp)\n",
        "            counter += 1\n",
        "    y = np.array(y)\n",
        "    y = y.reshape(y.shape[0], 8)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YNqk0hAabTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for train\n",
        "label_train = [i for i in range(0,1690)] #train\n",
        "start_train = {'neutral':130, 'disgust':260, 'sad':520, 'angry':780, 'fearful':1040, 'surprised':1170, 'calm':1430, 'happy':1690} #train\n",
        "mapping_train = {}\n",
        "i = 0\n",
        "for key, value in start_train.items():\n",
        "    while(i<value):\n",
        "        mapping_train[i] = key\n",
        "        i += 1\n",
        "#batch size means video\n",
        "def imageLoader_train(label_train, batch_size):\n",
        "\n",
        "    L = len(label_train)\n",
        "\n",
        "    #this line is just to make the generator infinite, keras needs that    \n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "            X = Dataset_loader_X_train(label_train[batch_start:limit])\n",
        "            Y = Dataset_loader_Y_train(label_train[batch_start:limit])\n",
        "\n",
        "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
        "\n",
        "            batch_start += batch_size  \n",
        "            batch_end += batch_size\n",
        "            if batch_end%20==0:\n",
        "              t=batch_end/20\n",
        "              cc=0\n",
        "              for key,value in start_train.items():\n",
        "                cc+=1\n",
        "                if cc==t:\n",
        "                  batch_start=start_train[key]\n",
        "                  batch_end=batch_start+1\n",
        "                  break\n",
        "def Dataset_loader_X_train(label_train):\n",
        "    RESIZE = 224\n",
        "    DIR = '/content/content/data/train/'\n",
        "    IMG = []\n",
        "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "    for i in label_train:\n",
        "        counter = 0\n",
        "        DIR2 = DIR + mapping_train[i] + '/' + str(i)\n",
        "        for IMAGE_NAME in (os.listdir(DIR2)):\n",
        "            if(counter == CONSTANT_FRAMES):\n",
        "                break\n",
        "            PATH = os.path.join(DIR2,IMAGE_NAME)\n",
        "            _, ftype = os.path.splitext(PATH)\n",
        "            if ftype == \".jpg\":\n",
        "                img = read(PATH)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img, (RESIZE,RESIZE))\n",
        "                IMG.append(np.array(img)/255.)\n",
        "            counter += 1\n",
        "    IMG = np.array(IMG)\n",
        "    IMG = IMG.reshape(IMG.shape[0], 224, 224, 1)\n",
        "    return IMG\n",
        "def Dataset_loader_Y_train(label_train):\n",
        "    DIR = '/content/content/data/train/'\n",
        "    y = []\n",
        "    dict_ = {'angry':1, 'sad':2, 'fearful':3, 'happy':4, 'neutral':5, 'surprised':6, 'disgust':7, 'calm':8}\n",
        "    for i in label_train:\n",
        "        counter = 0\n",
        "        DIR2 = DIR + mapping_train[i] + '/' + str(i)\n",
        "        for IMAGE_NAME in (os.listdir(DIR2)):\n",
        "            if(counter == CONSTANT_FRAMES):\n",
        "                break\n",
        "            temp = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "            temp[dict_[mapping_train[i]]-1] = 1\n",
        "            y.append(temp)\n",
        "            counter += 1\n",
        "    y = np.array(y)\n",
        "    y = y.reshape(y.shape[0], 8)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04JrqPlxjh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e92a97f-6d88-4d61-dd81-4628ecd72ed0"
      },
      "source": [
        "History = model.fit_generator(imageLoader_train(label_train, 1), steps_per_epoch = 160, epochs = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "160/160 [==============================] - 448s 3s/step - loss: 14.7078 - accuracy: 0.0875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LkzKqyayiDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.evaluate_generator(imageLoader_test(label_test, 1), steps=1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib5DKHCR0LFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e239e43-56ca-4907-add7-731c6634ccaf"
      },
      "source": [
        "print('Accuracy of given cnn-ds model:-', result[1]*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of given cnn-ds model:- 39.89911111 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrpC6AD3d2RK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(History.history['acc'])\n",
        "plt.plot(History.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggHvF3NU0PFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('model_dscnn', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdtJHKJTT7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/model_dscnn' '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBiMUmNnXDFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "fil = open('/content/model_dscnn', 'rb') \n",
        "model_ = pickle.loads(fil.read()) \n",
        "fil.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TSmhczthMp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/frame49.jpg'\n",
        "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "X = []\n",
        "IMG = []\n",
        "img = read(PATH)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = cv2.resize(img, (224,224))\n",
        "IMG.append(np.array(img)/255.)\n",
        "IMG = np.array(IMG)\n",
        "X = IMG.reshape(IMG.shape[0], 224, 224, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XwMzapGhjZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de97fdac-629f-4de0-cef8-3dbc0bf456bb"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INzUkCXKh1Oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model_.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShKdK13wh-Vm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c34845e4-67ec-4a4f-9c04-1036974b6ed1"
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FQvt2HIuB8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}